# setup 
```{r}
library(tidyverse)
library(readr)
library(dplyr)
library(randomForest)
library(tidymodels)
library(skimr)
library(yardstick)
library(caret)
library(xgboost)
library(mlr)
```

# loading data
```{r}
tester <- read.csv("data/daymet/finalWeatherandRegions.csv") 
```

# wrangling data
```{r}
field_data <- tester %>%
  mutate_if(is.character, as.factor) %>%
  dplyr::select(-irrigation, -loc, -lat, -lon) %>%
  drop_na()

```

# splitting data 
```{r}
set.seed(123)
# Put 80% of the data into the training set 
data_split <- initial_split(field_data, strata = "str_emmean", prop = 0.80)

# Create data frames for the two sets:
train_data <- training(data_split)

test_data  <- testing(data_split) 

# random forest 
rf_mod <- rand_forest(mode = "regression",  mtry = 104, trees = 72)
```


# modeling
# temporal scale: entire temporal scale
```{r entire temporal scale}
# all temporal scales 
set.seed(123)
preds <- train_data %>%
  dplyr::select(-c(year:loc)) 
  
rf_all_fit <-  rf_mod %>%
  set_engine("randomForest") %>%
  fit_xy(
    x = dplyr::select(preds, -str_emmean),
    y = preds$str_emmean
  )

# r^2 
train_predictions <- train_data %>%
  predict(rf_all_fit, .) %>%
  bind_cols(actual = train_data$str_emmean) %>%
  mutate(residuals = actual - .)

R2(train_predictions$.pred, train_data$str_emmean)
RMSE(train_predictions$.pred, train_data$str_emmean)


```

# estimating performance
```{r}
set.seed(123)
predicted_values <- predict(rf_all_fit, new_data = test_data)

plot_data <- test_data %>% 
  bind_cols(data.frame(Predicted = predicted_values)) %>%
  mutate(residual = str_emmean - .pred)

# residual vs year
plot_data %>%
  ggplot(aes(x=year, y=residual))+
  geom_point()+
  geom_hline(yintercept = c(-2,0,2), color = "red")

plot_data %>%
  filter(residual < -5) %>%
  dplyr::select(year, region, state, str_emmean, .pred)

# plot for actual VS predicted valuesp (point=test_data)
 plot_data %>%
  ggplot(aes(x = str_emmean, y = .pred)) +
  geom_point(aes(color = year)) + # changed from color = year 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Actual", y = "Predicted") +
  ggtitle("Actual vs. Predicted Values")

# R^2 / RMSE
set.seed(123)
R2(predicted_values, test_data$str_emmean)
RMSE(predicted_values$.pred, test_data$str_emmean)

# Extract the slope coefficient
lm_model  <- lm(str_emmean ~ .pred, data = plot_data)
slope <- coef(lm_model)[".pred"]
slope # 1.375308 might indiicates efficiently estimated actual values

```

# temporal scale: growing season
# training
```{r growing season}
# growing seasons
set.seed(123)
growingseason <- train_data %>%
  dplyr::select(-c(year:loc)) %>%
  dplyr::select(c(srad_mean_growingseason:prcp_sum_growingseason), str_emmean)

rf_growingseason_fit <- rf_mod %>%
  set_engine("randomForest") %>%
  fit_xy(
    x = dplyr::select(growingseason, -str_emmean),
    y = growingseason$str_emmean
  )

rf_growingseason_fit

# r^2
train_predictions_gs <- train_data %>%
  predict(rf_growingseason_fit, .) %>%
  bind_cols(actual = train_data$str_emmean) %>%
  mutate(residuals = actual - .)

R2(train_predictions_gs$.pred, train_data$str_emmean)
RMSE(train_predictions_gs$.pred, train_data$str_emmean)


```

```{r testing}
set.seed(123)
predicted_values_gs <- predict(rf_growingseason_fit, new_data = test_data)

plot_data_gs <- test_data %>%
  bind_cols(data.frame(Predicted = predicted_values_gs)) %>%
  mutate(residual = str_emmean - .pred)

# residual vs year
plot_data_gs %>%
  ggplot(aes(x=year, y=residual))+
  geom_point()+
  geom_hline(yintercept=c(-2,0,2), color="red")

plot_data_gs %>%
  filter(residual < -5) %>%
  dplyr::select(year, loc, str_emmean, .pred)

# plot for actual VS predicted values (point=test_data)
plot_data_gs %>%
  ggplot(aes(x = str_emmean, y = .pred)) +
  geom_point(aes(color=year)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Actual", y = "Predicted") +
  ggtitle("Growing Season: Actual vs. Predicted Values")

# R^2  / RMSE
R2(predicted_values_gs, test_data$str_emmean)
RMSE(predicted_values_gs$.pred, test_data$str_emmean)

# Extract the slope coefficient
lm_model_gs  <- lm(str_emmean ~ .pred, data = plot_data_gs)
slope_gs <- coef(lm_model_gs)[".pred"]
slope_gs # 1.096859  (efficient since close to 1)

```

# temporal scale: 4 months
```{r quadramonths}
quadramonths <- train_data %>%
  dplyr::select(-c(year:loc)) %>%
  dplyr::select(c(srad_mean_April_May_June_July:prcp_sum_August_September_October_November), str_emmean)

set.seed(123)
rf_quadra_fit <- rf_mod %>%
  set_engine("randomForest") %>%
  fit_xy(
    x = dplyr::select(quadramonths, -str_emmean),
    y = quadramonths$str_emmean
  )

rf_quadra_fit

# r^2 for training
train_predictions_quadra <- train_data %>%
  predict(rf_quadra_fit, .) %>%
  bind_cols(actual = train_data$str_emmean) %>%
  mutate(residuals = actual - .)

R2(train_predictions_quadra$.pred, train_data$str_emmean)
RMSE(train_predictions_quadra$.pred, train_data$str_emmean)
```

```{r testing}
set.seed(123)
predicted_values_quadra <- predict(rf_quadra_fit, new_data = test_data)

plot_data_quadra <- test_data %>%
  bind_cols(data.frame(Predicted = predicted_values_quadra)) %>%
  mutate(residual = str_emmean - .pred)

# residual vs year 
plot_data_quadra %>%
  ggplot(aes(x=year, y=residual))+
  geom_point()+
  geom_hline(yintercept=c(-2,0,2), color="red")

plot_data_gs %>%
  filter(residual < -5) %>%
  dplyr::select(year, loc, str_emmean, .pred)

# plot for actual VS predicted values (point=test_data)
plot_data_quadra %>%
  ggplot(aes(x = str_emmean, y = .pred)) +
  geom_point(aes(color=year)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Actual", y = "Predicted") +
  ggtitle("Every Four Months: Actual vs. Predicted Values")

# R^2 / RMSE 
R2(predicted_values_quadra, test_data$str_emmean)
RMSE(predicted_values_quadra$.pred, test_data$str_emmean)

# Extract the slope coefficient
lm_model_quadra  <- lm(str_emmean ~ .pred, data = plot_data_quadra)
slope_quadra <- coef(lm_model_quadra)[".pred"]
slope_quadra # 0.7295688
```

# Temporal Scale: bi monthly 
```{r bi monthly}
bimonths <- train_data %>%
  dplyr::select(-c(year:loc)) %>%
  dplyr::select(c(srad_mean_April_May:prcp_sum_October_November), str_emmean)

set.seed(123)
rf_bi_fit <- rf_mod %>%
  set_engine("randomForest") %>%
  fit_xy(
    x = dplyr::select(bimonths, -str_emmean),
    y = bimonths$str_emmean
  )

rf_bi_fit

# r^2 for training
train_predictions_bi <- train_data %>%
  predict(rf_bi_fit, .) %>%
  bind_cols(actual = train_data$str_emmean) %>%
  mutate(residuals = actual - .) 

R2(train_predictions_bi$.pred, train_data$str_emmean)
RMSE(train_predictions_bi$.pred, train_data$str_emmean)
```

```{r testing}
set.seed(123)
predicted_values_bi <- predict(rf_bi_fit, new_data = test_data)

plot_data_bi <- test_data %>%
  bind_cols(data.frame(Predicted = predicted_values_bi)) %>%
  mutate(residual = str_emmean - .pred)

# residual vs year 
plot_data_bi %>%
  ggplot(aes(x=year, y = residual)) + 
  geom_point() +
   geom_hline(yintercept=c(-2,0,2), color="red")

plot_data_bi %>%
  filter(residual < -5) %>%
  dplyr::select(year,loc ,str_emmean, .pred)


# plot for actual VS predicted values (point=test_data)
plot_data_bi %>%
  ggplot(aes(x = str_emmean, y=.pred)) +
  geom_point(aes(color=year)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Actual", y = "Predicted") +
  ggtitle("Bimonthly: Actual vs. Predicted Values")

R2(predicted_values_bi, test_data$str_emmean)
RMSE(predicted_values_bi$.pred, test_data$str_emmean)

# Extract the slope coefficient
lm_model_bi  <- lm(str_emmean ~ .pred, data = plot_data_bi)
slope_bi <- coef(lm_model_bi)[".pred"]
slope_bi #1.083225 
```

# Temporal Scale: monthly
```{r monthly}
set.seed(123)
months <- train_data %>%
  dplyr::select(-c(year:loc)) %>%
  dplyr::select(c(srad_mean_April:prcp_sum_November), str_emmean)

rf_monthly_fit <- rf_mod %>%
  set_engine("randomForest") %>%
  fit_xy(
    x = dplyr::select(months, -str_emmean),
    y = months$str_emmean
  )

rf_monthly_fit

# r^2 for training
train_predictions_monthly <- train_data %>%
  predict(rf_monthly_fit, .) %>%
  bind_cols(actual = train_data$str_emmean) 

R2(train_predictions_monthly$.pred, train_data$str_emmean)
RMSE(train_predictions_monthly$.pred, train_data$str_emmean)

```


```{r testing}
predicted_values_monthly <- predict(rf_monthly_fit, new_data = test_data)

plot_data_monthly <- test_data %>%
  bind_cols(data.frame(Predicted = predicted_values_monthly)) %>%
  mutate(residual = str_emmean - .pred)

# residual vs year 
plot_data_monthly %>%
  ggplot(aes(x=year, y =residual)) + 
  geom_point() + 
  geom_hline(yintercept=c(-2,0,2), color="red")

# plot for actual VS predicted values (point=test_data)
plot_data_monthly  %>%
  ggplot(aes(x = str_emmean, y=.pred)) +
  geom_point(aes(color=year)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Actual", y = "Predicted") +
  ggtitle("Monthly: Actual vs. Predicted Values")


R2(predicted_values_monthly, test_data$str_emmean)
RMSE(predicted_values_monthly$.pred, test_data$str_emmean)

# Extract the slope coefficient
lm_model_monthly  <- lm(str_emmean ~ .pred, data = plot_data_monthly)
slope_monthly  <- coef(lm_model_monthly)[".pred"]
slope_monthly  # 0.9390052 
```


# region 
```{r}
location <- train_data %>%
  dplyr::select(-c(year:loc)) %>%
  dplyr::select(c(region:state), str_emmean)

rf_location_fit <- rf_mod %>%
  set_engine("randomForest") %>%
  fit_xy(
    x = dplyr::select(location, -str_emmean),
    y = location$str_emmean
  )
train_predictions_location <- train_data %>%
  predict(rf_location_fit, .) %>%
  bind_cols(actual = train_data$str_emmean)

# r^2 for training
R2(train_predictions_location$.pred, train_data$str_emmean)
RMSE(train_predictions_location$.pred, train_data$str_emmean)
```


# tuning hyper params using grid search 
```{r grid search}
# when doing this i removed loc from train_data or field_data so BEWARE OF ERRORS! 
rf_learner <- makeLearner("classif.randomForest", predict.type = "prob")

trainTask <- makeClassifTask(data = train_data, target = "region")
# grid search to find hyper params
rf_param <- makeParamSet(
  makeIntegerParam("ntree", lower=10, upper=floor(0.1*nrow(train_data))),
  makeIntegerParam("mtry", lower = floor((ncol(train_data)-1)/3),
                           upper = ncol(train_data)))

# random search for 10 new_iteration_results
rancontrol <- makeTuneControlRandom(maxit=10L)

# set 3 fold cross validation
set_cv <- makeResampleDesc("CV", iters=3L)

rf_tune <- tuneParams(learner = rf_learner,
                      resampling = set_cv,
                      task = trainTask,
                      par.set = rf_param,
                      control = rancontrol,
                      measures = acc)
```

